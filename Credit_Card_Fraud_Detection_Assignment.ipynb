{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit Card Fraud Detection Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1he8zxZNbBV48lyZA1Z33Rv9YejKnk39g",
      "authorship_tag": "ABX9TyP4ty4K/8wKgybf4VQ+g9RR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmadshabbir862/DL_Assignments/blob/main/Credit_Card_Fraud_Detection_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NPN3r8UqiNW"
      },
      "source": [
        "##**Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq0wgS5-34qe",
        "outputId": "7656983b-6170-4ddc-a311-1355f3dd6019"
      },
      "source": [
        "%cd/content/drive/MyDrive/AI_assignment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/AI_assignment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mJ6XlVF4E5M"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF1Rq0XM4K2T"
      },
      "source": [
        "card_data = pd.read_csv('./creditcard.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "Rl3VFeZI4bv6",
        "outputId": "f4561919-eb26-462f-d2cf-9a08c5acd31e"
      },
      "source": [
        "card_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLPNaCu5qw91"
      },
      "source": [
        "##**Checking Missing Values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK_BqKDJ42Fn",
        "outputId": "1878de42-5a29-44a3-f46a-b87cf431df56"
      },
      "source": [
        "np.where(card_data.applymap(lambda x: x ==''))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([], dtype=int64), array([], dtype=int64))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVJ8PPiy6MJs",
        "outputId": "ad59ae7c-a428-4d76-d5a6-a63bfabffce0"
      },
      "source": [
        "card_data.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      float64\n",
              "V1        float64\n",
              "V2        float64\n",
              "V3        float64\n",
              "V4        float64\n",
              "V5        float64\n",
              "V6        float64\n",
              "V7        float64\n",
              "V8        float64\n",
              "V9        float64\n",
              "V10       float64\n",
              "V11       float64\n",
              "V12       float64\n",
              "V13       float64\n",
              "V14       float64\n",
              "V15       float64\n",
              "V16       float64\n",
              "V17       float64\n",
              "V18       float64\n",
              "V19       float64\n",
              "V20       float64\n",
              "V21       float64\n",
              "V22       float64\n",
              "V23       float64\n",
              "V24       float64\n",
              "V25       float64\n",
              "V26       float64\n",
              "V27       float64\n",
              "V28       float64\n",
              "Amount    float64\n",
              "Class       int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "NAiymetj5Igb",
        "outputId": "8b042bd4-d3b0-4f6f-c0ea-3073eae65266"
      },
      "source": [
        "card_data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>3.919560e-15</td>\n",
              "      <td>5.688174e-16</td>\n",
              "      <td>-8.769071e-15</td>\n",
              "      <td>2.782312e-15</td>\n",
              "      <td>-1.552563e-15</td>\n",
              "      <td>2.010663e-15</td>\n",
              "      <td>-1.694249e-15</td>\n",
              "      <td>-1.927028e-16</td>\n",
              "      <td>-3.137024e-15</td>\n",
              "      <td>1.768627e-15</td>\n",
              "      <td>9.170318e-16</td>\n",
              "      <td>-1.810658e-15</td>\n",
              "      <td>1.693438e-15</td>\n",
              "      <td>1.479045e-15</td>\n",
              "      <td>3.482336e-15</td>\n",
              "      <td>1.392007e-15</td>\n",
              "      <td>-7.528491e-16</td>\n",
              "      <td>4.328772e-16</td>\n",
              "      <td>9.049732e-16</td>\n",
              "      <td>5.085503e-16</td>\n",
              "      <td>1.537294e-16</td>\n",
              "      <td>7.959909e-16</td>\n",
              "      <td>5.367590e-16</td>\n",
              "      <td>4.458112e-15</td>\n",
              "      <td>1.453003e-15</td>\n",
              "      <td>1.699104e-15</td>\n",
              "      <td>-3.660161e-16</td>\n",
              "      <td>-1.206049e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>1.088850e+00</td>\n",
              "      <td>1.020713e+00</td>\n",
              "      <td>9.992014e-01</td>\n",
              "      <td>9.952742e-01</td>\n",
              "      <td>9.585956e-01</td>\n",
              "      <td>9.153160e-01</td>\n",
              "      <td>8.762529e-01</td>\n",
              "      <td>8.493371e-01</td>\n",
              "      <td>8.381762e-01</td>\n",
              "      <td>8.140405e-01</td>\n",
              "      <td>7.709250e-01</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>-2.458826e+01</td>\n",
              "      <td>-4.797473e+00</td>\n",
              "      <td>-1.868371e+01</td>\n",
              "      <td>-5.791881e+00</td>\n",
              "      <td>-1.921433e+01</td>\n",
              "      <td>-4.498945e+00</td>\n",
              "      <td>-1.412985e+01</td>\n",
              "      <td>-2.516280e+01</td>\n",
              "      <td>-9.498746e+00</td>\n",
              "      <td>-7.213527e+00</td>\n",
              "      <td>-5.449772e+01</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>-5.354257e-01</td>\n",
              "      <td>-7.624942e-01</td>\n",
              "      <td>-4.055715e-01</td>\n",
              "      <td>-6.485393e-01</td>\n",
              "      <td>-4.255740e-01</td>\n",
              "      <td>-5.828843e-01</td>\n",
              "      <td>-4.680368e-01</td>\n",
              "      <td>-4.837483e-01</td>\n",
              "      <td>-4.988498e-01</td>\n",
              "      <td>-4.562989e-01</td>\n",
              "      <td>-2.117214e-01</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>-9.291738e-02</td>\n",
              "      <td>-3.275735e-02</td>\n",
              "      <td>1.400326e-01</td>\n",
              "      <td>-1.356806e-02</td>\n",
              "      <td>5.060132e-02</td>\n",
              "      <td>4.807155e-02</td>\n",
              "      <td>6.641332e-02</td>\n",
              "      <td>-6.567575e-02</td>\n",
              "      <td>-3.636312e-03</td>\n",
              "      <td>3.734823e-03</td>\n",
              "      <td>-6.248109e-02</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>4.539234e-01</td>\n",
              "      <td>7.395934e-01</td>\n",
              "      <td>6.182380e-01</td>\n",
              "      <td>6.625050e-01</td>\n",
              "      <td>4.931498e-01</td>\n",
              "      <td>6.488208e-01</td>\n",
              "      <td>5.232963e-01</td>\n",
              "      <td>3.996750e-01</td>\n",
              "      <td>5.008067e-01</td>\n",
              "      <td>4.589494e-01</td>\n",
              "      <td>1.330408e-01</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>2.374514e+01</td>\n",
              "      <td>1.201891e+01</td>\n",
              "      <td>7.848392e+00</td>\n",
              "      <td>7.126883e+00</td>\n",
              "      <td>1.052677e+01</td>\n",
              "      <td>8.877742e+00</td>\n",
              "      <td>1.731511e+01</td>\n",
              "      <td>9.253526e+00</td>\n",
              "      <td>5.041069e+00</td>\n",
              "      <td>5.591971e+00</td>\n",
              "      <td>3.942090e+01</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Time            V1  ...         Amount          Class\n",
              "count  284807.000000  2.848070e+05  ...  284807.000000  284807.000000\n",
              "mean    94813.859575  3.919560e-15  ...      88.349619       0.001727\n",
              "std     47488.145955  1.958696e+00  ...     250.120109       0.041527\n",
              "min         0.000000 -5.640751e+01  ...       0.000000       0.000000\n",
              "25%     54201.500000 -9.203734e-01  ...       5.600000       0.000000\n",
              "50%     84692.000000  1.810880e-02  ...      22.000000       0.000000\n",
              "75%    139320.500000  1.315642e+00  ...      77.165000       0.000000\n",
              "max    172792.000000  2.454930e+00  ...   25691.160000       1.000000\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nubbNzTnrtg8"
      },
      "source": [
        "##**Splitting Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5I9o-jvLJ5f"
      },
      "source": [
        "non_fraud= card_data[card_data['Class']==0]\n",
        "fraud=card_data[card_data['Class']==1]\n",
        "non_fraud = non_fraud.sample(fraud.shape[0])\n",
        "data = fraud.append(non_fraud, ignore_index=True)\n",
        "x_data=data.drop(columns='Class', axis=0)\n",
        "label = data['Class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHQG2XMyOvXw",
        "outputId": "d0fe4683-4d0d-485a-b8e2-e6e1b5b69112"
      },
      "source": [
        "non_fraud.shape, fraud.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((492, 31), (492, 31))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzwYdvFEO4_3"
      },
      "source": [
        "train_data, test_data, train_label, test_label = train_test_split(x_data, label, test_size=0.3, random_state=1, stratify=label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-LT9hZSr6dt"
      },
      "source": [
        "##**Standardiz Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j9oEN3K-o83"
      },
      "source": [
        "mean = train_data.mean(axis=0)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "test_data -= mean\n",
        "test_data /= std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx-GfZB3pxso"
      },
      "source": [
        "##**Building the Natwork**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fegsu8-G_Czu"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(10, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(8, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(6, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mv_WY0esmAl"
      },
      "source": [
        "###**Compilition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0fj95XbAPT2"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctevs0J-s162"
      },
      "source": [
        "###**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIMSJIW2Cn1T",
        "outputId": "329c7506-ab06-4c96-bbfc-60edb17c1368"
      },
      "source": [
        "model.fit(train_data, train_label, epochs=100, validation_split=0.3)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 19ms/step - loss: 0.7776 - accuracy: 0.5065 - val_loss: 0.6959 - val_accuracy: 0.5845\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7892 - accuracy: 0.5183 - val_loss: 0.6827 - val_accuracy: 0.6618\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7480 - accuracy: 0.4939 - val_loss: 0.6699 - val_accuracy: 0.7198\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7324 - accuracy: 0.5288 - val_loss: 0.6586 - val_accuracy: 0.7198\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.7318 - accuracy: 0.5476 - val_loss: 0.6462 - val_accuracy: 0.7536\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6828 - accuracy: 0.5767 - val_loss: 0.6361 - val_accuracy: 0.7778\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6179 - accuracy: 0.6238 - val_loss: 0.6241 - val_accuracy: 0.8019\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.6123 - val_loss: 0.6133 - val_accuracy: 0.8068\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.6095 - val_loss: 0.6059 - val_accuracy: 0.8068\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6507 - accuracy: 0.6524 - val_loss: 0.5989 - val_accuracy: 0.8116\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6191 - accuracy: 0.6293 - val_loss: 0.5893 - val_accuracy: 0.8213\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6430 - accuracy: 0.6784 - val_loss: 0.5824 - val_accuracy: 0.8213\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5964 - accuracy: 0.6802 - val_loss: 0.5718 - val_accuracy: 0.8502\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5827 - accuracy: 0.6554 - val_loss: 0.5566 - val_accuracy: 0.8551\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6236 - accuracy: 0.6642 - val_loss: 0.5545 - val_accuracy: 0.8647\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5898 - accuracy: 0.6739 - val_loss: 0.5416 - val_accuracy: 0.8647\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5602 - accuracy: 0.7101 - val_loss: 0.5308 - val_accuracy: 0.8792\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5971 - accuracy: 0.6950 - val_loss: 0.5230 - val_accuracy: 0.8937\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5849 - accuracy: 0.7110 - val_loss: 0.5153 - val_accuracy: 0.8889\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5632 - accuracy: 0.7135 - val_loss: 0.5080 - val_accuracy: 0.8889\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7374 - val_loss: 0.4929 - val_accuracy: 0.8889\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5676 - accuracy: 0.6938 - val_loss: 0.4868 - val_accuracy: 0.8889\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5501 - accuracy: 0.6765 - val_loss: 0.4733 - val_accuracy: 0.8937\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7212 - val_loss: 0.4664 - val_accuracy: 0.8937\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7614 - val_loss: 0.4534 - val_accuracy: 0.8937\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5065 - accuracy: 0.7400 - val_loss: 0.4473 - val_accuracy: 0.8937\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7268 - val_loss: 0.4435 - val_accuracy: 0.8937\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5315 - accuracy: 0.7428 - val_loss: 0.4434 - val_accuracy: 0.8937\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5207 - accuracy: 0.7146 - val_loss: 0.4388 - val_accuracy: 0.8937\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5392 - accuracy: 0.7249 - val_loss: 0.4372 - val_accuracy: 0.9082\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.6941 - val_loss: 0.4323 - val_accuracy: 0.9034\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4933 - accuracy: 0.7751 - val_loss: 0.4259 - val_accuracy: 0.9082\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.8064 - val_loss: 0.4157 - val_accuracy: 0.9227\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5072 - accuracy: 0.7737 - val_loss: 0.4139 - val_accuracy: 0.9227\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4791 - accuracy: 0.7517 - val_loss: 0.4088 - val_accuracy: 0.9227\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7918 - val_loss: 0.4006 - val_accuracy: 0.9227\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5043 - accuracy: 0.7684 - val_loss: 0.3963 - val_accuracy: 0.9227\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7447 - val_loss: 0.3905 - val_accuracy: 0.9227\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7732 - val_loss: 0.3870 - val_accuracy: 0.9275\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.7521 - val_loss: 0.3937 - val_accuracy: 0.9275\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7520 - val_loss: 0.3934 - val_accuracy: 0.9275\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7879 - val_loss: 0.3918 - val_accuracy: 0.9275\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7856 - val_loss: 0.3874 - val_accuracy: 0.9275\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7287 - val_loss: 0.3823 - val_accuracy: 0.9275\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7908 - val_loss: 0.3847 - val_accuracy: 0.9275\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7774 - val_loss: 0.3860 - val_accuracy: 0.9275\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.7686 - val_loss: 0.3811 - val_accuracy: 0.9275\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8182 - val_loss: 0.3796 - val_accuracy: 0.9324\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8048 - val_loss: 0.3775 - val_accuracy: 0.9324\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4541 - accuracy: 0.7811 - val_loss: 0.3843 - val_accuracy: 0.9324\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.7691 - val_loss: 0.3849 - val_accuracy: 0.9324\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8112 - val_loss: 0.3805 - val_accuracy: 0.9324\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8029 - val_loss: 0.3848 - val_accuracy: 0.9275\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.8132 - val_loss: 0.3871 - val_accuracy: 0.9324\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8086 - val_loss: 0.3876 - val_accuracy: 0.9324\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8267 - val_loss: 0.3933 - val_accuracy: 0.9324\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8028 - val_loss: 0.3948 - val_accuracy: 0.9324\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8115 - val_loss: 0.3953 - val_accuracy: 0.9324\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3911 - accuracy: 0.8393 - val_loss: 0.3969 - val_accuracy: 0.9324\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3880 - accuracy: 0.8425 - val_loss: 0.3970 - val_accuracy: 0.9324\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3853 - accuracy: 0.8189 - val_loss: 0.4004 - val_accuracy: 0.9324\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3663 - accuracy: 0.8351 - val_loss: 0.3975 - val_accuracy: 0.9324\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8246 - val_loss: 0.4031 - val_accuracy: 0.9324\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3727 - accuracy: 0.8279 - val_loss: 0.4096 - val_accuracy: 0.9324\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.8323 - val_loss: 0.4114 - val_accuracy: 0.9324\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3850 - accuracy: 0.8404 - val_loss: 0.4129 - val_accuracy: 0.9324\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8465 - val_loss: 0.4135 - val_accuracy: 0.9324\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8247 - val_loss: 0.4183 - val_accuracy: 0.9324\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3609 - accuracy: 0.8315 - val_loss: 0.4194 - val_accuracy: 0.9324\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8114 - val_loss: 0.4164 - val_accuracy: 0.9324\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3245 - accuracy: 0.8769 - val_loss: 0.4196 - val_accuracy: 0.9324\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.8044 - val_loss: 0.4292 - val_accuracy: 0.9324\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8071 - val_loss: 0.4389 - val_accuracy: 0.9372\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8134 - val_loss: 0.4395 - val_accuracy: 0.9372\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7697 - val_loss: 0.4431 - val_accuracy: 0.9372\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3507 - accuracy: 0.8555 - val_loss: 0.4439 - val_accuracy: 0.9372\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.8229 - val_loss: 0.4509 - val_accuracy: 0.9372\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.8207 - val_loss: 0.4602 - val_accuracy: 0.9372\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8362 - val_loss: 0.4617 - val_accuracy: 0.9372\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8484 - val_loss: 0.4649 - val_accuracy: 0.9372\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8749 - val_loss: 0.4685 - val_accuracy: 0.9372\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3309 - accuracy: 0.8737 - val_loss: 0.4745 - val_accuracy: 0.9372\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3397 - accuracy: 0.8595 - val_loss: 0.4745 - val_accuracy: 0.9372\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3116 - accuracy: 0.8734 - val_loss: 0.4740 - val_accuracy: 0.9372\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8155 - val_loss: 0.4782 - val_accuracy: 0.9420\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8507 - val_loss: 0.4816 - val_accuracy: 0.9420\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8247 - val_loss: 0.4910 - val_accuracy: 0.9420\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8657 - val_loss: 0.4975 - val_accuracy: 0.9420\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8465 - val_loss: 0.4974 - val_accuracy: 0.9420\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3793 - accuracy: 0.8241 - val_loss: 0.5007 - val_accuracy: 0.9420\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8367 - val_loss: 0.5064 - val_accuracy: 0.9420\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8449 - val_loss: 0.5070 - val_accuracy: 0.9420\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.2860 - accuracy: 0.8978 - val_loss: 0.5097 - val_accuracy: 0.9420\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3563 - accuracy: 0.8368 - val_loss: 0.5111 - val_accuracy: 0.9420\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8375 - val_loss: 0.5110 - val_accuracy: 0.9420\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3596 - accuracy: 0.8386 - val_loss: 0.5175 - val_accuracy: 0.9469\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.3309 - accuracy: 0.8378 - val_loss: 0.5202 - val_accuracy: 0.9469\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3082 - accuracy: 0.8724 - val_loss: 0.5279 - val_accuracy: 0.9469\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3179 - accuracy: 0.8440 - val_loss: 0.5286 - val_accuracy: 0.9469\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.3555 - accuracy: 0.8231 - val_loss: 0.5357 - val_accuracy: 0.9469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f269917bcd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iybHWqWBtlBR"
      },
      "source": [
        "##**Eveluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9LfaD3FDGRh",
        "outputId": "97f94727-3784-407a-f748-3e6fb7748847"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_data, test_label)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.9291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGlD3aJStVuU"
      },
      "source": [
        "##**Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEOLs9exE-_1"
      },
      "source": [
        "x = model.predict(test_data)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX5LxaMVHrSm",
        "outputId": "98296280-773d-4a35-8359-2c22abb284ef"
      },
      "source": [
        "x[:9]"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.20866042],\n",
              "       [0.27896923],\n",
              "       [0.23783615],\n",
              "       [0.16224334],\n",
              "       [1.        ],\n",
              "       [0.25631708],\n",
              "       [1.        ],\n",
              "       [0.13898197],\n",
              "       [1.        ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iD4ehWaHuUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b58ef4be-6736-4a88-a1e2-3274b7456459"
      },
      "source": [
        "test_label[:9]"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "902    0\n",
              "747    0\n",
              "701    0\n",
              "827    0\n",
              "358    1\n",
              "794    0\n",
              "273    1\n",
              "824    0\n",
              "11     1\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGmFeRtXtJso"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}