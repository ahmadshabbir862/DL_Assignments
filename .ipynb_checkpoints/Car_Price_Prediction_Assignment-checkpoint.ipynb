{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ahmadshabbir862/DL_Assignments/blob/main/Car_Price_Prediction_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_HsWVrWvDNP"
   },
   "source": [
    "# Car Price Prediction::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Neq61yUOvDNV"
   },
   "source": [
    "Download dataset from this link:\n",
    "\n",
    "https://www.kaggle.com/hellbuoy/car-price-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "errs9eyZvDNW"
   },
   "source": [
    "# Problem Statement::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCu6NRLVvDNX"
   },
   "source": [
    "A Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts.\n",
    "\n",
    "They have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\n",
    "\n",
    "Which variables are significant in predicting the price of a car\n",
    "How well those variables describe the price of a car\n",
    "Based on various market surveys, the consulting firm has gathered a large data set of different types of cars across the America market.\n",
    "\n",
    "# task::\n",
    "We are required to model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables. They can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-vI6CymvDNX"
   },
   "source": [
    "# WORKFLOW ::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRvlK8RBvDNX"
   },
   "source": [
    "1.Load Data\n",
    "\n",
    "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
    "\n",
    "3.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
    "\n",
    "4.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
    "\n",
    "5.Compilation Step (Note : Its a Regression problem , select loss , metrics according to it)\n",
    "6.Train the Model with Epochs (100) and validate it\n",
    "\n",
    "7.If the model gets overfit tune your model by changing the units , No. of layers , activation function , epochs , add dropout layer or add Regularizer according to the need .\n",
    "\n",
    "8.Evaluation Step\n",
    "\n",
    "9.Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "duXMXXhZvDNY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "hLI6o0H7eLrA",
    "outputId": "9681b388-1d8f-4a48-f467-c72b2d06fcae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-05c6c263-f8a3-4fbd-8fb8-df8017b1c5e2\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-05c6c263-f8a3-4fbd-8fb8-df8017b1c5e2\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving CarPrice_Assignment.csv to CarPrice_Assignment.csv\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "d8DgwpSKeWSK",
    "outputId": "0f61f748-3541-47e2-b37a-e20ebdd176c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_ID</th>\n",
       "      <th>symboling</th>\n",
       "      <th>CarName</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>doornumber</th>\n",
       "      <th>carbody</th>\n",
       "      <th>drivewheel</th>\n",
       "      <th>enginelocation</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>carlength</th>\n",
       "      <th>carwidth</th>\n",
       "      <th>carheight</th>\n",
       "      <th>curbweight</th>\n",
       "      <th>enginetype</th>\n",
       "      <th>cylindernumber</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>fuelsystem</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>alfa-romero giulia</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>dohc</td>\n",
       "      <td>four</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>alfa-romero stelvio</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>dohc</td>\n",
       "      <td>four</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>alfa-romero Quadrifoglio</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>171.2</td>\n",
       "      <td>65.5</td>\n",
       "      <td>52.4</td>\n",
       "      <td>2823</td>\n",
       "      <td>ohcv</td>\n",
       "      <td>six</td>\n",
       "      <td>152</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 100 ls</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2337</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 100ls</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2824</td>\n",
       "      <td>ohc</td>\n",
       "      <td>five</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   car_ID  symboling                   CarName  ... citympg highwaympg    price\n",
       "0       1          3        alfa-romero giulia  ...      21         27  13495.0\n",
       "1       2          3       alfa-romero stelvio  ...      21         27  16500.0\n",
       "2       3          1  alfa-romero Quadrifoglio  ...      19         26  16500.0\n",
       "3       4          2               audi 100 ls  ...      24         30  13950.0\n",
       "4       5          2                audi 100ls  ...      18         22  17450.0\n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data = pd.read_csv(io.BytesIO(uploaded['CarPrice_Assignment.csv']))\n",
    "car_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "euCqFI3Y0l6h",
    "outputId": "702190ee-255b-421b-9bd1-aa77fc9a4937"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "car_ID              False\n",
       "symboling           False\n",
       "CarName             False\n",
       "fueltype            False\n",
       "aspiration          False\n",
       "doornumber          False\n",
       "carbody             False\n",
       "drivewheel          False\n",
       "enginelocation      False\n",
       "wheelbase           False\n",
       "carlength           False\n",
       "carwidth            False\n",
       "carheight           False\n",
       "curbweight          False\n",
       "enginetype          False\n",
       "cylindernumber      False\n",
       "enginesize          False\n",
       "fuelsystem          False\n",
       "boreratio           False\n",
       "stroke              False\n",
       "compressionratio    False\n",
       "horsepower          False\n",
       "peakrpm             False\n",
       "citympg             False\n",
       "highwaympg          False\n",
       "price               False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UwZgj7IIvXRm"
   },
   "outputs": [],
   "source": [
    "# correct the name error in audi 100 ls\n",
    "car_data.iloc[3,2] = 'audi 100ls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BN6vZOZr5EpP",
    "outputId": "d138d686-cb71-4efa-aa1a-24627ff6119b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['car_ID', 'symboling', 'CarName', 'fueltype', 'aspiration',\n",
       "       'doornumber', 'carbody', 'drivewheel', 'enginelocation', 'wheelbase',\n",
       "       'carlength', 'carwidth', 'carheight', 'curbweight', 'enginetype',\n",
       "       'cylindernumber', 'enginesize', 'fuelsystem', 'boreratio', 'stroke',\n",
       "       'compressionratio', 'horsepower', 'peakrpm', 'citympg', 'highwaympg',\n",
       "       'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r1cCvWApvDNZ",
    "outputId": "2a2e054a-68de-4ff2-a1e2-747bc46b31fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "car_ID                int64\n",
       "symboling             int64\n",
       "CarName              object\n",
       "fueltype             object\n",
       "aspiration           object\n",
       "doornumber           object\n",
       "carbody              object\n",
       "drivewheel           object\n",
       "enginelocation       object\n",
       "wheelbase           float64\n",
       "carlength           float64\n",
       "carwidth            float64\n",
       "carheight           float64\n",
       "curbweight            int64\n",
       "enginetype           object\n",
       "cylindernumber       object\n",
       "enginesize            int64\n",
       "fuelsystem           object\n",
       "boreratio           float64\n",
       "stroke              float64\n",
       "compressionratio    float64\n",
       "horsepower            int64\n",
       "peakrpm               int64\n",
       "citympg               int64\n",
       "highwaympg            int64\n",
       "price               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H6NTeH-qvDNa",
    "outputId": "073b92fb-1c58-4ac2-a7b1-f7e0542adfaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if there are empty cells, if there are then row and column indexes will be returned where values are empty or missing\n",
    "np.where(car_data.applymap(lambda x: x ==''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gBJA5-NyX-zj"
   },
   "outputs": [],
   "source": [
    "# drop useless column\n",
    "car_data.drop(columns = ['car_ID'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nqvKX-JyvDNa"
   },
   "outputs": [],
   "source": [
    "# onehot encode all catagorical columns\n",
    "final_car = pd.get_dummies(car_data, columns=['symboling','CarName','fueltype',\t'aspiration',\t'doornumber',\t'carbody',\t'drivewheel',\t'enginelocation',\t'enginetype',\t'cylindernumber',\t'fuelsystem'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "hgIZc8J6UswW",
    "outputId": "01e73949-4aa9-49b6-a277-c0426304a618"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>carlength</th>\n",
       "      <th>carwidth</th>\n",
       "      <th>carheight</th>\n",
       "      <th>curbweight</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "      <th>symboling_-2</th>\n",
       "      <th>symboling_-1</th>\n",
       "      <th>symboling_0</th>\n",
       "      <th>symboling_1</th>\n",
       "      <th>symboling_2</th>\n",
       "      <th>symboling_3</th>\n",
       "      <th>CarName_Nissan versa</th>\n",
       "      <th>CarName_alfa-romero Quadrifoglio</th>\n",
       "      <th>CarName_alfa-romero giulia</th>\n",
       "      <th>CarName_alfa-romero stelvio</th>\n",
       "      <th>CarName_audi 100ls</th>\n",
       "      <th>CarName_audi 4000</th>\n",
       "      <th>CarName_audi 5000</th>\n",
       "      <th>CarName_audi 5000s (diesel)</th>\n",
       "      <th>CarName_audi fox</th>\n",
       "      <th>CarName_bmw 320i</th>\n",
       "      <th>CarName_bmw x1</th>\n",
       "      <th>CarName_bmw x3</th>\n",
       "      <th>CarName_bmw x4</th>\n",
       "      <th>CarName_bmw x5</th>\n",
       "      <th>CarName_bmw z4</th>\n",
       "      <th>CarName_buick century</th>\n",
       "      <th>CarName_buick century luxus (sw)</th>\n",
       "      <th>CarName_buick century special</th>\n",
       "      <th>CarName_buick electra 225 custom</th>\n",
       "      <th>CarName_buick opel isuzu deluxe</th>\n",
       "      <th>...</th>\n",
       "      <th>CarName_vw dasher</th>\n",
       "      <th>CarName_vw rabbit</th>\n",
       "      <th>fueltype_diesel</th>\n",
       "      <th>fueltype_gas</th>\n",
       "      <th>aspiration_std</th>\n",
       "      <th>aspiration_turbo</th>\n",
       "      <th>doornumber_four</th>\n",
       "      <th>doornumber_two</th>\n",
       "      <th>carbody_convertible</th>\n",
       "      <th>carbody_hardtop</th>\n",
       "      <th>carbody_hatchback</th>\n",
       "      <th>carbody_sedan</th>\n",
       "      <th>carbody_wagon</th>\n",
       "      <th>drivewheel_4wd</th>\n",
       "      <th>drivewheel_fwd</th>\n",
       "      <th>drivewheel_rwd</th>\n",
       "      <th>enginelocation_front</th>\n",
       "      <th>enginelocation_rear</th>\n",
       "      <th>enginetype_dohc</th>\n",
       "      <th>enginetype_dohcv</th>\n",
       "      <th>enginetype_l</th>\n",
       "      <th>enginetype_ohc</th>\n",
       "      <th>enginetype_ohcf</th>\n",
       "      <th>enginetype_ohcv</th>\n",
       "      <th>enginetype_rotor</th>\n",
       "      <th>cylindernumber_eight</th>\n",
       "      <th>cylindernumber_five</th>\n",
       "      <th>cylindernumber_four</th>\n",
       "      <th>cylindernumber_six</th>\n",
       "      <th>cylindernumber_three</th>\n",
       "      <th>cylindernumber_twelve</th>\n",
       "      <th>cylindernumber_two</th>\n",
       "      <th>fuelsystem_1bbl</th>\n",
       "      <th>fuelsystem_2bbl</th>\n",
       "      <th>fuelsystem_4bbl</th>\n",
       "      <th>fuelsystem_idi</th>\n",
       "      <th>fuelsystem_mfi</th>\n",
       "      <th>fuelsystem_mpfi</th>\n",
       "      <th>fuelsystem_spdi</th>\n",
       "      <th>fuelsystem_spfi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>98.756585</td>\n",
       "      <td>174.049268</td>\n",
       "      <td>65.907805</td>\n",
       "      <td>53.724878</td>\n",
       "      <td>2555.565854</td>\n",
       "      <td>126.907317</td>\n",
       "      <td>3.329756</td>\n",
       "      <td>3.255415</td>\n",
       "      <td>10.142537</td>\n",
       "      <td>104.117073</td>\n",
       "      <td>5125.121951</td>\n",
       "      <td>25.219512</td>\n",
       "      <td>30.751220</td>\n",
       "      <td>13276.710571</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0.107317</td>\n",
       "      <td>0.326829</td>\n",
       "      <td>0.263415</td>\n",
       "      <td>0.156098</td>\n",
       "      <td>0.131707</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.819512</td>\n",
       "      <td>0.180488</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.029268</td>\n",
       "      <td>0.039024</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.468293</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.043902</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.370732</td>\n",
       "      <td>0.985366</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0.058537</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.058537</td>\n",
       "      <td>0.721951</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.063415</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.053659</td>\n",
       "      <td>0.775610</td>\n",
       "      <td>0.117073</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.053659</td>\n",
       "      <td>0.321951</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.458537</td>\n",
       "      <td>0.043902</td>\n",
       "      <td>0.004878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.021776</td>\n",
       "      <td>12.337289</td>\n",
       "      <td>2.145204</td>\n",
       "      <td>2.443522</td>\n",
       "      <td>520.680204</td>\n",
       "      <td>41.642693</td>\n",
       "      <td>0.270844</td>\n",
       "      <td>0.313597</td>\n",
       "      <td>3.972040</td>\n",
       "      <td>39.544167</td>\n",
       "      <td>476.985643</td>\n",
       "      <td>6.542142</td>\n",
       "      <td>6.886443</td>\n",
       "      <td>7988.852332</td>\n",
       "      <td>0.120377</td>\n",
       "      <td>0.310274</td>\n",
       "      <td>0.470202</td>\n",
       "      <td>0.441564</td>\n",
       "      <td>0.363836</td>\n",
       "      <td>0.339000</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.120377</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.098531</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.098531</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.297446</td>\n",
       "      <td>0.297446</td>\n",
       "      <td>0.385535</td>\n",
       "      <td>0.385535</td>\n",
       "      <td>0.497483</td>\n",
       "      <td>0.497483</td>\n",
       "      <td>0.168970</td>\n",
       "      <td>0.194127</td>\n",
       "      <td>0.475361</td>\n",
       "      <td>0.500215</td>\n",
       "      <td>0.328031</td>\n",
       "      <td>0.205380</td>\n",
       "      <td>0.493865</td>\n",
       "      <td>0.484183</td>\n",
       "      <td>0.120377</td>\n",
       "      <td>0.120377</td>\n",
       "      <td>0.235330</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.235330</td>\n",
       "      <td>0.449134</td>\n",
       "      <td>0.261054</td>\n",
       "      <td>0.244304</td>\n",
       "      <td>0.138655</td>\n",
       "      <td>0.154635</td>\n",
       "      <td>0.225894</td>\n",
       "      <td>0.418201</td>\n",
       "      <td>0.322294</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.138655</td>\n",
       "      <td>0.225894</td>\n",
       "      <td>0.468368</td>\n",
       "      <td>0.120377</td>\n",
       "      <td>0.297446</td>\n",
       "      <td>0.069843</td>\n",
       "      <td>0.499498</td>\n",
       "      <td>0.205380</td>\n",
       "      <td>0.069843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>86.600000</td>\n",
       "      <td>141.100000</td>\n",
       "      <td>60.300000</td>\n",
       "      <td>47.800000</td>\n",
       "      <td>1488.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4150.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>5118.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>94.500000</td>\n",
       "      <td>166.300000</td>\n",
       "      <td>64.100000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2145.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>4800.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>7788.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>173.200000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>54.100000</td>\n",
       "      <td>2414.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>3.290000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>5200.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10295.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>102.400000</td>\n",
       "      <td>183.100000</td>\n",
       "      <td>66.900000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>2935.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>16503.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120.900000</td>\n",
       "      <td>208.100000</td>\n",
       "      <td>72.300000</td>\n",
       "      <td>59.800000</td>\n",
       "      <td>4066.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>4.170000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>45400.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        wheelbase   carlength  ...  fuelsystem_spdi  fuelsystem_spfi\n",
       "count  205.000000  205.000000  ...       205.000000       205.000000\n",
       "mean    98.756585  174.049268  ...         0.043902         0.004878\n",
       "std      6.021776   12.337289  ...         0.205380         0.069843\n",
       "min     86.600000  141.100000  ...         0.000000         0.000000\n",
       "25%     94.500000  166.300000  ...         0.000000         0.000000\n",
       "50%     97.000000  173.200000  ...         0.000000         0.000000\n",
       "75%    102.400000  183.100000  ...         0.000000         0.000000\n",
       "max    120.900000  208.100000  ...         1.000000         1.000000\n",
       "\n",
       "[8 rows x 204 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check statistical data to see abnormal values and outliers\n",
    "final_car.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "q_sikuUQAGD4"
   },
   "outputs": [],
   "source": [
    "np.random.seed(512)\n",
    "msk = np.random.rand(len(final_car)) < 0.72\n",
    "train_total = final_car[msk]\n",
    "test_total = final_car[~msk]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSjX5UckTu1_",
    "outputId": "ec7611ae-f244-4aef-ad5d-99a5f1a63ad3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "print(len(train_total))\n",
    "print(len(test_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "a4njPsfOfLJP",
    "outputId": "e28ca616-1542-4469-95f4-923792192124"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>carlength</th>\n",
       "      <th>carwidth</th>\n",
       "      <th>carheight</th>\n",
       "      <th>curbweight</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "      <th>symboling_-2</th>\n",
       "      <th>symboling_-1</th>\n",
       "      <th>symboling_0</th>\n",
       "      <th>symboling_1</th>\n",
       "      <th>symboling_2</th>\n",
       "      <th>symboling_3</th>\n",
       "      <th>CarName_Nissan versa</th>\n",
       "      <th>CarName_alfa-romero Quadrifoglio</th>\n",
       "      <th>CarName_alfa-romero giulia</th>\n",
       "      <th>CarName_alfa-romero stelvio</th>\n",
       "      <th>CarName_audi 100ls</th>\n",
       "      <th>CarName_audi 4000</th>\n",
       "      <th>CarName_audi 5000</th>\n",
       "      <th>CarName_audi 5000s (diesel)</th>\n",
       "      <th>CarName_audi fox</th>\n",
       "      <th>CarName_bmw 320i</th>\n",
       "      <th>CarName_bmw x1</th>\n",
       "      <th>CarName_bmw x3</th>\n",
       "      <th>CarName_bmw x4</th>\n",
       "      <th>CarName_bmw x5</th>\n",
       "      <th>CarName_bmw z4</th>\n",
       "      <th>CarName_buick century</th>\n",
       "      <th>CarName_buick century luxus (sw)</th>\n",
       "      <th>CarName_buick century special</th>\n",
       "      <th>CarName_buick electra 225 custom</th>\n",
       "      <th>CarName_buick opel isuzu deluxe</th>\n",
       "      <th>...</th>\n",
       "      <th>CarName_vw dasher</th>\n",
       "      <th>CarName_vw rabbit</th>\n",
       "      <th>fueltype_diesel</th>\n",
       "      <th>fueltype_gas</th>\n",
       "      <th>aspiration_std</th>\n",
       "      <th>aspiration_turbo</th>\n",
       "      <th>doornumber_four</th>\n",
       "      <th>doornumber_two</th>\n",
       "      <th>carbody_convertible</th>\n",
       "      <th>carbody_hardtop</th>\n",
       "      <th>carbody_hatchback</th>\n",
       "      <th>carbody_sedan</th>\n",
       "      <th>carbody_wagon</th>\n",
       "      <th>drivewheel_4wd</th>\n",
       "      <th>drivewheel_fwd</th>\n",
       "      <th>drivewheel_rwd</th>\n",
       "      <th>enginelocation_front</th>\n",
       "      <th>enginelocation_rear</th>\n",
       "      <th>enginetype_dohc</th>\n",
       "      <th>enginetype_dohcv</th>\n",
       "      <th>enginetype_l</th>\n",
       "      <th>enginetype_ohc</th>\n",
       "      <th>enginetype_ohcf</th>\n",
       "      <th>enginetype_ohcv</th>\n",
       "      <th>enginetype_rotor</th>\n",
       "      <th>cylindernumber_eight</th>\n",
       "      <th>cylindernumber_five</th>\n",
       "      <th>cylindernumber_four</th>\n",
       "      <th>cylindernumber_six</th>\n",
       "      <th>cylindernumber_three</th>\n",
       "      <th>cylindernumber_twelve</th>\n",
       "      <th>cylindernumber_two</th>\n",
       "      <th>fuelsystem_1bbl</th>\n",
       "      <th>fuelsystem_2bbl</th>\n",
       "      <th>fuelsystem_4bbl</th>\n",
       "      <th>fuelsystem_idi</th>\n",
       "      <th>fuelsystem_mfi</th>\n",
       "      <th>fuelsystem_mpfi</th>\n",
       "      <th>fuelsystem_spdi</th>\n",
       "      <th>fuelsystem_spfi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>130</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.5</td>\n",
       "      <td>171.2</td>\n",
       "      <td>65.5</td>\n",
       "      <td>52.4</td>\n",
       "      <td>2823</td>\n",
       "      <td>152</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2337</td>\n",
       "      <td>109</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.4</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2824</td>\n",
       "      <td>136</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wheelbase  carlength  ...  fuelsystem_spdi  fuelsystem_spfi\n",
       "0       88.6      168.8  ...                0                0\n",
       "1       88.6      168.8  ...                0                0\n",
       "2       94.5      171.2  ...                0                0\n",
       "3       99.8      176.6  ...                0                0\n",
       "4       99.4      176.6  ...                0                0\n",
       "\n",
       "[5 rows x 204 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "BeYOhn1Eiams",
    "outputId": "0cf0b5b2-0dee-45cf-b4ce-8209ff9bf02e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>carlength</th>\n",
       "      <th>carwidth</th>\n",
       "      <th>carheight</th>\n",
       "      <th>curbweight</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "      <th>symboling_-2</th>\n",
       "      <th>symboling_-1</th>\n",
       "      <th>symboling_0</th>\n",
       "      <th>symboling_1</th>\n",
       "      <th>symboling_2</th>\n",
       "      <th>symboling_3</th>\n",
       "      <th>CarName_Nissan versa</th>\n",
       "      <th>CarName_alfa-romero Quadrifoglio</th>\n",
       "      <th>CarName_alfa-romero giulia</th>\n",
       "      <th>CarName_alfa-romero stelvio</th>\n",
       "      <th>CarName_audi 100ls</th>\n",
       "      <th>CarName_audi 4000</th>\n",
       "      <th>CarName_audi 5000</th>\n",
       "      <th>CarName_audi 5000s (diesel)</th>\n",
       "      <th>CarName_audi fox</th>\n",
       "      <th>CarName_bmw 320i</th>\n",
       "      <th>CarName_bmw x1</th>\n",
       "      <th>CarName_bmw x3</th>\n",
       "      <th>CarName_bmw x4</th>\n",
       "      <th>CarName_bmw x5</th>\n",
       "      <th>CarName_bmw z4</th>\n",
       "      <th>CarName_buick century</th>\n",
       "      <th>CarName_buick century luxus (sw)</th>\n",
       "      <th>CarName_buick century special</th>\n",
       "      <th>CarName_buick electra 225 custom</th>\n",
       "      <th>CarName_buick opel isuzu deluxe</th>\n",
       "      <th>...</th>\n",
       "      <th>CarName_vw dasher</th>\n",
       "      <th>CarName_vw rabbit</th>\n",
       "      <th>fueltype_diesel</th>\n",
       "      <th>fueltype_gas</th>\n",
       "      <th>aspiration_std</th>\n",
       "      <th>aspiration_turbo</th>\n",
       "      <th>doornumber_four</th>\n",
       "      <th>doornumber_two</th>\n",
       "      <th>carbody_convertible</th>\n",
       "      <th>carbody_hardtop</th>\n",
       "      <th>carbody_hatchback</th>\n",
       "      <th>carbody_sedan</th>\n",
       "      <th>carbody_wagon</th>\n",
       "      <th>drivewheel_4wd</th>\n",
       "      <th>drivewheel_fwd</th>\n",
       "      <th>drivewheel_rwd</th>\n",
       "      <th>enginelocation_front</th>\n",
       "      <th>enginelocation_rear</th>\n",
       "      <th>enginetype_dohc</th>\n",
       "      <th>enginetype_dohcv</th>\n",
       "      <th>enginetype_l</th>\n",
       "      <th>enginetype_ohc</th>\n",
       "      <th>enginetype_ohcf</th>\n",
       "      <th>enginetype_ohcv</th>\n",
       "      <th>enginetype_rotor</th>\n",
       "      <th>cylindernumber_eight</th>\n",
       "      <th>cylindernumber_five</th>\n",
       "      <th>cylindernumber_four</th>\n",
       "      <th>cylindernumber_six</th>\n",
       "      <th>cylindernumber_three</th>\n",
       "      <th>cylindernumber_twelve</th>\n",
       "      <th>cylindernumber_two</th>\n",
       "      <th>fuelsystem_1bbl</th>\n",
       "      <th>fuelsystem_2bbl</th>\n",
       "      <th>fuelsystem_4bbl</th>\n",
       "      <th>fuelsystem_idi</th>\n",
       "      <th>fuelsystem_mfi</th>\n",
       "      <th>fuelsystem_mpfi</th>\n",
       "      <th>fuelsystem_spdi</th>\n",
       "      <th>fuelsystem_spfi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>98.276866</td>\n",
       "      <td>173.336567</td>\n",
       "      <td>65.744776</td>\n",
       "      <td>53.717164</td>\n",
       "      <td>2497.231343</td>\n",
       "      <td>124.097015</td>\n",
       "      <td>3.306194</td>\n",
       "      <td>3.257201</td>\n",
       "      <td>9.947090</td>\n",
       "      <td>102.619403</td>\n",
       "      <td>5183.208955</td>\n",
       "      <td>25.328358</td>\n",
       "      <td>30.873134</td>\n",
       "      <td>12857.242537</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.126866</td>\n",
       "      <td>0.291045</td>\n",
       "      <td>0.305970</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.126866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.917910</td>\n",
       "      <td>0.828358</td>\n",
       "      <td>0.171642</td>\n",
       "      <td>0.589552</td>\n",
       "      <td>0.410448</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.037313</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.126866</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.313433</td>\n",
       "      <td>0.977612</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.111940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.067164</td>\n",
       "      <td>0.335821</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.740594</td>\n",
       "      <td>11.659812</td>\n",
       "      <td>2.048163</td>\n",
       "      <td>2.363842</td>\n",
       "      <td>468.741106</td>\n",
       "      <td>38.490673</td>\n",
       "      <td>0.274552</td>\n",
       "      <td>0.293990</td>\n",
       "      <td>3.708538</td>\n",
       "      <td>36.251169</td>\n",
       "      <td>500.936868</td>\n",
       "      <td>6.154375</td>\n",
       "      <td>6.524012</td>\n",
       "      <td>7789.078346</td>\n",
       "      <td>0.121709</td>\n",
       "      <td>0.334071</td>\n",
       "      <td>0.455949</td>\n",
       "      <td>0.462546</td>\n",
       "      <td>0.342284</td>\n",
       "      <td>0.334071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.148497</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121709</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275531</td>\n",
       "      <td>0.275531</td>\n",
       "      <td>0.378484</td>\n",
       "      <td>0.378484</td>\n",
       "      <td>0.493761</td>\n",
       "      <td>0.493761</td>\n",
       "      <td>0.148497</td>\n",
       "      <td>0.190240</td>\n",
       "      <td>0.471378</td>\n",
       "      <td>0.501653</td>\n",
       "      <td>0.334071</td>\n",
       "      <td>0.207588</td>\n",
       "      <td>0.481273</td>\n",
       "      <td>0.465629</td>\n",
       "      <td>0.148497</td>\n",
       "      <td>0.148497</td>\n",
       "      <td>0.237822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148497</td>\n",
       "      <td>0.436778</td>\n",
       "      <td>0.286611</td>\n",
       "      <td>0.237822</td>\n",
       "      <td>0.148497</td>\n",
       "      <td>0.148497</td>\n",
       "      <td>0.237822</td>\n",
       "      <td>0.413348</td>\n",
       "      <td>0.316476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148497</td>\n",
       "      <td>0.251245</td>\n",
       "      <td>0.474049</td>\n",
       "      <td>0.121709</td>\n",
       "      <td>0.275531</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.499130</td>\n",
       "      <td>0.207588</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>86.600000</td>\n",
       "      <td>144.600000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>48.800000</td>\n",
       "      <td>1819.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>4150.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>5195.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>94.500000</td>\n",
       "      <td>166.925000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2145.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>3.092500</td>\n",
       "      <td>3.112500</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>4800.000000</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>7775.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>96.500000</td>\n",
       "      <td>172.200000</td>\n",
       "      <td>65.400000</td>\n",
       "      <td>54.100000</td>\n",
       "      <td>2390.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>3.290000</td>\n",
       "      <td>3.290000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>5200.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>9749.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100.400000</td>\n",
       "      <td>177.800000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>2810.250000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>115.750000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>15611.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120.900000</td>\n",
       "      <td>208.100000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>59.800000</td>\n",
       "      <td>3900.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>45400.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        wheelbase   carlength  ...  fuelsystem_spdi  fuelsystem_spfi\n",
       "count  134.000000  134.000000  ...       134.000000            134.0\n",
       "mean    98.276866  173.336567  ...         0.044776              0.0\n",
       "std      5.740594   11.659812  ...         0.207588              0.0\n",
       "min     86.600000  144.600000  ...         0.000000              0.0\n",
       "25%     94.500000  166.925000  ...         0.000000              0.0\n",
       "50%     96.500000  172.200000  ...         0.000000              0.0\n",
       "75%    100.400000  177.800000  ...         0.000000              0.0\n",
       "max    120.900000  208.100000  ...         1.000000              0.0\n",
       "\n",
       "[8 rows x 204 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check statistical overview if there are some outliers and abnormal values\n",
    "train_total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iwv0k5MXkjiU",
    "outputId": "0d1d7cb4-1b84-4e9e-9b4d-d5ed4a7dd80c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wheelbase          float64\n",
      "carlength          float64\n",
      "carwidth           float64\n",
      "carheight          float64\n",
      "curbweight           int64\n",
      "                    ...   \n",
      "fuelsystem_idi       uint8\n",
      "fuelsystem_mfi       uint8\n",
      "fuelsystem_mpfi      uint8\n",
      "fuelsystem_spdi      uint8\n",
      "fuelsystem_spfi      uint8\n",
      "Length: 204, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_total.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "UMVbWuxTzEUh"
   },
   "outputs": [],
   "source": [
    "# get our price labels and store in another dataframe\n",
    "train_label = train_total.loc[:,'price']\n",
    "test_label = test_total.loc[:,'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ok93gWC0V7RC",
    "outputId": "818962ce-aa04-4980-8e79-bb3962478c7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      13495.0\n",
       "1      16500.0\n",
       "2      16500.0\n",
       "3      13950.0\n",
       "4      17450.0\n",
       "        ...   \n",
       "198    18420.0\n",
       "200    16845.0\n",
       "202    21485.0\n",
       "203    22470.0\n",
       "204    22625.0\n",
       "Name: price, Length: 134, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0pj0hGliz6ld"
   },
   "outputs": [],
   "source": [
    "# drop price from oroginal training and test dataset , as price is not needed there\n",
    "test_data= test_total.drop(columns = ['price'])\n",
    "train_data= train_total.drop(columns = ['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7uw8yz0e1RjS",
    "outputId": "d3a1dab5-7a1b-4f07-a024-2fadd1e6ce0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 203)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "1h5vhggTyRyw"
   },
   "outputs": [],
   "source": [
    "mean = train_data.iloc[:,0:13].mean(axis=0) # taking the mean of \n",
    "train_data.iloc[:,0:13] -= mean\n",
    "std = train_data.iloc[:,0:13].std(axis=0)\n",
    "train_data.iloc[:,0:13] /= std\n",
    "test_data.iloc[:,0:13] -= mean\n",
    "test_data.iloc[:,0:13] /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "CZYfOs0cfaGE"
   },
   "outputs": [],
   "source": [
    "mean_label = train_label.mean()\n",
    "train_label -= mean_label\n",
    "std_label = train_label.std()\n",
    "train_label /= std_label\n",
    "test_label -= mean_label\n",
    "test_label /= std_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mc7B1amLmsx",
    "outputId": "611d1bed-816c-4b08-8d78-333192c20aa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12857.242537313432\n"
     ]
    }
   ],
   "source": [
    "print(mean_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8uIRUHEw7g4",
    "outputId": "c5102b0f-7fda-4b24-8570-d5680dc06c11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     0.642172\n",
       "11    0.522239\n",
       "12    1.041556\n",
       "16    3.653546\n",
       "18   -0.989365\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejyRo91P9Klh"
   },
   "outputs": [],
   "source": [
    "#store in numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "eLTpt0qn-R5y"
   },
   "outputs": [],
   "source": [
    "test = np.array(test_data.iloc[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "6ym52Tun-vhn"
   },
   "outputs": [],
   "source": [
    "train = np.array(train_data.iloc[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "TnFGfxGn_d1b"
   },
   "outputs": [],
   "source": [
    "test_l= np.array(test_label.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "kklQZ0za_qZb"
   },
   "outputs": [],
   "source": [
    "train_l= np.array(train_label.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVbXDcGe5cY2",
    "outputId": "48e67266-9ef3-49c8-bd51-60205178063b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 203)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm416iVz953_"
   },
   "source": [
    "\n",
    "# Models section\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "EqOJjh8n8fMU"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "def build_model(act):\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(10, activation= act,input_shape=(train.shape[1],)))\n",
    "  model.add(layers.Dense(8, activation= act))\n",
    "  model.add(layers.Dense(6, activation= act))\n",
    "  model.add(layers.Dense(1))\n",
    "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZKs2Axd19Rsx",
    "outputId": "0f9db897-f53d-4e75-c352-f82ba831a18c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                2040      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 2,189\n",
      "Trainable params: 2,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_model('relu').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShTLMMUPWE2E",
    "outputId": "966a0dac-3324-4109-bc27-8725ec8a4f93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 10)                2040      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 2,189\n",
      "Trainable params: 2,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_model('tanh').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "iLNbzXjKqGSw"
   },
   "outputs": [],
   "source": [
    "# Regularized model\n",
    "from keras import regularizers\n",
    "def build_model_regular(act):\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(10, activation= act,kernel_regularizer= regularizers.l1_l2(l1=0.001, l2=0.001),input_shape=(train.shape[1],)))\n",
    "  model.add(layers.Dense(8, activation= act,kernel_regularizer= regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "  model.add(layers.Dense(6, activation= act,kernel_regularizer= regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "  model.add(layers.Dense(1))\n",
    "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afnNh94NrncJ",
    "outputId": "591f44ca-35ff-4e49-bd91-1a491e91929d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 10)                2040      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 2,189\n",
      "Trainable params: 2,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_model_regular('tanh').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "hKOI8TLD1SHd"
   },
   "outputs": [],
   "source": [
    "# dropout model\n",
    "from keras import regularizers\n",
    "def build_model_drop(act):\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Dense(10, activation= act,input_shape=(train.shape[1],)))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Dense(8, activation= act))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Dense(6, activation= act))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Dense(1))\n",
    "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwAm7RMr_eMa"
   },
   "source": [
    "## **K Fold validation section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTizsf6znpb7",
    "outputId": "63893c62-888e-4e91-e764-37d9ba036e46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc24db6f680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 1\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc2510dac20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 2\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc24ae12950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 3\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc24db95710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "#k fold validation with relu\n",
    "# 141/4\n",
    "import numpy as np\n",
    "k =  4\n",
    "num_val_samples = len(train) // k\n",
    "num_epochs = 100\n",
    "all_scores_relu = []\n",
    "for i in range(k):\n",
    "  print('processing fold #', i)\n",
    "  val_data = train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  val_targets = train_l[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  partial_train_data = np.concatenate([train[:i * num_val_samples],train[(i + 1) * num_val_samples:]],  axis=0)\n",
    "  # print(partial_train_data)\n",
    "  partial_train_targets = np.concatenate([train_l[:i * num_val_samples],train_l[(i + 1) * num_val_samples:]],axis=0)\n",
    "  model = build_model('relu')\n",
    "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
    "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "  all_scores_relu.append(val_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HaXgBohaz4WI",
    "outputId": "77c879cb-ace9-4cc2-e38b-5f584ff7b5f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc255b557a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 1\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc24adfddd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 2\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc24adfdb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 3\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc259c78950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# 141/4\n",
    "#k fold validation with tanh\n",
    "import numpy as np\n",
    "k =  4\n",
    "num_val_samples = len(train) // k\n",
    "num_epochs = 100\n",
    "all_scores_tanh = []\n",
    "for i in range(k):\n",
    "  print('processing fold #', i)\n",
    "  val_data = train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  val_targets = train_l[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  partial_train_data = np.concatenate([train[:i * num_val_samples],train[(i + 1) * num_val_samples:]],  axis=0)\n",
    "  # print(partial_train_data)\n",
    "  partial_train_targets = np.concatenate([train_l[:i * num_val_samples],train_l[(i + 1) * num_val_samples:]],axis=0)\n",
    "  model = build_model('tanh')\n",
    "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
    "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "  all_scores_tanh.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SD6TuagJb54U",
    "outputId": "a5a3142e-151d-407f-9daa-0685613ed593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc2454025f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 1\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc245402320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 2\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc245402f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 3\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc259c0e440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "#k-fold validtion with regularization\n",
    "import numpy as np\n",
    "k =  4\n",
    "num_val_samples = len(train) // k\n",
    "num_epochs = 100\n",
    "all_scores_regular = []\n",
    "for i in range(k):\n",
    "  print('processing fold #', i)\n",
    "  val_data = train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  val_targets = train_l[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  partial_train_data = np.concatenate([train[:i * num_val_samples],train[(i + 1) * num_val_samples:]],  axis=0)\n",
    "  # print(partial_train_data)\n",
    "  partial_train_targets = np.concatenate([train_l[:i * num_val_samples],train_l[(i + 1) * num_val_samples:]],axis=0)\n",
    "  model = build_model_regular('relu')\n",
    "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
    "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "  all_scores_regular.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3ENBDAMrHtb",
    "outputId": "2aef7d04-d450-4d14-b9f7-223a2adeb884"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc259c11950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 1\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc245c7f560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 2\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc24db95680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "processing fold # 3\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc24a91bef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "#k-fold validtion with dropout\n",
    "import numpy as np\n",
    "k =  4\n",
    "num_val_samples = len(train) // k\n",
    "num_epochs = 100\n",
    "all_scores_drop = []\n",
    "for i in range(k):\n",
    "  print('processing fold #', i)\n",
    "  val_data = train[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  val_targets = train_l[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  partial_train_data = np.concatenate([train[:i * num_val_samples],train[(i + 1) * num_val_samples:]],  axis=0)\n",
    "  # print(partial_train_data)\n",
    "  partial_train_targets = np.concatenate([train_l[:i * num_val_samples],train_l[(i + 1) * num_val_samples:]],axis=0)\n",
    "  model = build_model_drop('relu')\n",
    "  model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
    "  val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "  all_scores_drop.append(val_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNxMnoqoAYd-"
   },
   "source": [
    "##**Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VORrpehRb7UR",
    "outputId": "2c2cc12b-46ad-4d8c-f027-f4f917eedb11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1538 - mae: 0.2850\n"
     ]
    }
   ],
   "source": [
    "model_tanh = build_model('tanh')\n",
    "model_tanh.fit(train, train_l,epochs= 80, batch_size=1, verbose=0)\n",
    "test_mse_score, test_mae_score = model_tanh.evaluate(test, test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ttydi9BzUnf5",
    "outputId": "90c82797-4b3b-43aa-f6e4-6548fa5dee2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc24db8fc20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1486 - mae: 0.2698\n"
     ]
    }
   ],
   "source": [
    "model_relu = build_model('relu')\n",
    "model_relu.fit(train, train_l,epochs= 80, batch_size=1, verbose=0)\n",
    "test_mse_score, test_mae_score = model_relu.evaluate(test, test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oZFYcfHftNlY",
    "outputId": "730ec0d4-2cbc-433b-b93d-6edc30a9e893"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1486 - mae: 0.2698\n"
     ]
    }
   ],
   "source": [
    "model_regular = build_model_regular('relu')\n",
    "model_regular.fit(train, train_l,epochs= 80, batch_size=1, verbose=0)\n",
    "test_mse_score, test_mae_score = model_relu.evaluate(test, test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ELSZLSCb0g7c",
    "outputId": "12807d54-b133-4589-93d2-8f49187c4219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1486 - mae: 0.2698\n"
     ]
    }
   ],
   "source": [
    "model_drop = build_model_drop('relu')\n",
    "model_drop.fit(train, train_l,epochs= 80, batch_size=1, verbose=0)\n",
    "test_mse_score, test_mae_score = model_relu.evaluate(test, test_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TV42POJyA-Na"
   },
   "source": [
    "##**Prediction**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "ofX9VqMVbhBC"
   },
   "outputs": [],
   "source": [
    "x_tanh = model_tanh.predict(test[5].reshape(1,test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNBUOF1eK2DY",
    "outputId": "6bf0b0f1-9197-4b20-c12b-50e6f72381a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10446.552]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tanh * std_label + mean_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--R_tOuOcv67"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Z0UyL_LOImw"
   },
   "outputs": [],
   "source": [
    "x_relu = model_relu.predict(test[5].reshape(1,test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJnnzVWTb5MV",
    "outputId": "9adca08c-fd95-43b7-ae29-6c450436bff1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6364.9175]], dtype=float32)"
      ]
     },
     "execution_count": 696,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_relu * std_label + mean_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2st4c4KwvdVA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlQRNOo0tb8J",
    "outputId": "3dff56c3-ff46-4baa-9724-6b9e688c59ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc259c11d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6862.3516]], dtype=float32)"
      ]
     },
     "execution_count": 697,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_regular = model_regular.predict(test[5].reshape(1,test.shape[1]))\n",
    "x_regular * std_label + mean_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uW5Y65pP0qET",
    "outputId": "7c930488-fe40-45ff-b887-395ee9ab4be5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc24db73560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11282.872]], dtype=float32)"
      ]
     },
     "execution_count": 699,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_drop = model_drop.predict(test[5].reshape(1,test.shape[1]))\n",
    "x_drop * std_label + mean_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bdo-oAvV7gt",
    "outputId": "ef6c90d2-e1e2-44a7-e680-00cfa9455ca4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7609.000199706916"
      ]
     },
     "execution_count": 700,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_l[5]* std_label + mean_label"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Car_Price_Prediction_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
